% last updated in April 2002 by Antje Endemann
% Based on CVPR 07 and LNCS, with modifications by DAF, AZ and elle, 2008 and AA, 2010, and CC, 2011; TT, 2014; AAS, 2016

\documentclass[runningheads]{llncs}
\usepackage{graphicx}
\usepackage{amsmath,amssymb} % define this before the line numbering.
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{ruler}
\usepackage{CJK}
\usepackage{color}
\usepackage[width=122mm,left=12mm,paperwidth=146mm,height=193mm,top=12mm,paperheight=217mm]{geometry}
\begin{document}

% \renewcommand\thelinenumber{\color[rgb]{0.2,0.5,0.8}\normalfont\sffamily\scriptsize\arabic{linenumber}\color[rgb]{0,0,0}}
% \renewcommand\makeLineNumber {\hss\thelinenumber\ \hspace{6mm} \rlap{\hskip\textwidth\ \hspace{6.5mm}\thelinenumber}}
% \linenumbers
\pagestyle{headings}
\mainmatter
\def\ECCV16SubNumber{***}  % Insert your submission number here

\title{Unsupervised Deep Domain Adaptation on People Detection} % Replace with your title

\titlerunning{ECCV-16 submission ID \ECCV16SubNumber}

\authorrunning{ECCV-16 submission ID \ECCV16SubNumber}

\author{Anonymous ECCV submission}
\institute{Paper ID \ECCV16SubNumber}


\maketitle

\begin{CJK*}{GBK}{song}

\begin{abstract}
这篇论文提出了基于无监督场景迁移下的在密集人群中人头检测的问题。也就是给定一个在原场景充分训练好的深度神经网络模型，如何在待迁移场景没有任何标记数据的情况下，训练一个能够识别待迁移场景中人物的模型。首先，我们利用迭代算法来自动标记待迁移场景中的人物。由于自动标记出来的人物数据中存在错误数据，假阳性的数据比例会随着训练迅速增加，影响到整个网络。因此我们将原场景中的标记数据加入到训练数据中，来抑制错误数据。同时，我们将神经网络最后的全连通层等价转化为两个子层。在新添加的子层上加入非监督的正则化函数来防止训练过程中的过拟合。跟将原场景中训练的原模型在没有利用待迁移场景的数据来微调得到的结果相比，我们提出的方法将待迁移场景中人物检测的召回率提高了xx,同时precision只从xx掉到xx。与此同时，我们将我们的算法运用到了标准的迁移学习基准数据库Office数据库，我们的方法在监督场景迁移喝非监督场景迁移都取得了最好的结果。
\keywords{无监督场景迁移，深度卷积神经网络，人物检测}
\end{abstract}

　　

\section{Introduction}

深度卷积神经网络在计算机视觉的任务上有非常突出的表现，但是，大部分的任务都需要大量的标记数据。像著名的PASCAL VOC和MS COCO，需要上千万的带标记的图片数据来完成训练的过程。在监控的运用中，比如人物检测，这个人工标记的过程就更加繁重了，因为需要标记到具体的位置。时至今日，世界上又有着无数的摄像头来担任监控的功能。然而，由于监控场景变化巨大，它受到背景，光线，视角，清晰度等等一系列的不稳定因素的影响，这就使得对于所有的监控场景进行人工标记这个工作更加的不可实施。在人物检测的任务中，需要上万的数据来训练一个好的检测神经网络。

当待迁移场景标记数据非常的少，甚至没有的情况下，场景迁移的任务就是帮忙减少所需要的有标记的数据的数量，当我们在原场景有大量的标记数据，那么这个迁移就需要考虑到原场景和待迁移场景之间的联系。大部分传统的场景迁移的算法\cite{saenko2010adapting,kulis2011you,gopalan2011domain,huang2006correcting,gretton2009covariate}都尝试找到原场景和待迁移场景之间的共同特征，或者将特征投射到高维空间中和子空间中。最近，也有其他工作\cite{wang2014scene,zeng2014deep,hattori2015learning}提出了通过深度网络来学习基于特殊场景的检测工具。在我们的人物检测的任务中，我们尝试着将在原场景中充分训练的深度网络迁移到一个待迁移场景，这个待迁移场景并没有任何标记数据。

在这篇文章中，我们提出了基于人物检测的无监督场景迁移的新算法。使用原场景下的原模型进行初始化，我们首先利用迭代算法来自动标记待迁移场景的图片作为伪真实数据。在每一次迭代中，待迁移场景的模型被更新并用来自动标记下一个迭代需要的训练数据。然后，由于缺乏真阴性数据和伪阳性数据，自动标记数据中的错误将导致伪阳性的比例迅速上升，同时进一步影响到了召回率的提高。为了消除数据噪声的影响，我们提出了两个方法来正则化深度网络的训练。一方面，我们将来自原场景的有标记数据的图片加入了自动标记的数据中，来弥补真阴性数据的不足。另一方面，我们将深度网络中最后的全连通层的操作切分为两个子运算--元素点乘和求和。最后的全连通层也因此可以转化为两个子层，元素点乘层和求和层。基于此，一个无监督的正则化函数可以被添加到深度网络中作为无监督的损失函数来防止伪阳性结果的迅速增加以及增强召回率。

在人物检测的任务之外，我们也添加了基于标准迁移学习基准数据库的实验来评估我们的算法的适用性。我们的算法的迁移结果同时在监督和无监督的设置下超过了之前发布的其他人的工作，这证明了我们的迁移算法有足够的灵活度来处理检测和分类的任务。

这篇文章的贡献有这样三个方面：
\begin{itemize}
\item  我们提出了一个可行的解决方案来将在原场景充分训练的深度模型迁移到待迁移场景，而待迁移场景并不需要任何标记数据。这使得深度网络在不同监控情况下的部署变得更为容易。
\item 由于大部分的算法都关注于最后一层的特征向量，我们往后一步来研究全连通层，并将最后一层全连通层转化为元素点乘层和求和层。因此一个无监督正则化函数可以加到元素点乘层，这样可以在抑制伪阳性和增加召回率方面取得更好的效果。
\item 我们在标准迁移学习基准数据库的实验也表明了我们在其他深度场景迁移的任务中也可以取得好的结果。
\end{itemize}

这篇文章剩下的部分是这样组织的。首先章节\ref{section:Relate Work}回顾了相关的工作，章节 \ref{section:Our Approach}给出了算法的细节部分，实验部分的结果在章节 \ref{section:Experiment Results} 中做出介绍。章节\ref{section:Conclusions} 总结了这篇论文。


\section{Relate Work}
\label{section:Relate Work}

在许多检测的工作中，在原场景中的大量数据的训练下得到的模型直接拿来检测待迁移场景的图片。他们假设待迁移场景的图片数据是原场景中图片数据的子集。然而当待迁移场景的数据分布跟原场景的数据分布差别很大时，原模型的表现会下降很多。场景迁移致力于得到更好的模型。

许多场景迁移的工作致力于找到原场景和待迁移场景之间的共同特征。Saenko et al. \cite{saenko2010adapting,kulis2011you}提出了一个基于线性变换的算法和一个基础核变化的算法来减少场景之间的变化。Gopalan et al. \cite{gopalan2011domain}将特征向量映射到Grassmann manifold而不是直接在元数据的特征上进行操作。或者，Mesnil et al. \cite{mesnil2012unsupervised}使用迁移学习的算法来获得好的数据特征表示。然而这些方法都相当的局限，因为他们并没有学习基于特殊场景的特征来增加准确率。我们的正则化函数受到了这些工作的启发。

另外一组场景迁移的工作\cite{huang2006correcting,gretton2009covariate,gong2013connecting}是将原场景的数据分布跟待迁移场景的数据分布弄得尽量相似。在这些工作中，Maximum Mean Discrepancy (MMD)被用到作为重新从原场景中挑选数据的评估依据，来使得其于待迁移场景的数据分布尽量相似。在工作
\cite{ghifary2014domain}中，MMD作为正则化工具加入到模型中以减少数据分布之间的差别。

同时，在学习基于特殊场景学习的检测算法也有一些工作。Wang et al.\cite{wang2014scene,zeng2014deep}利用了上下文的信息来计算检测物体的置信度，同时他也提出了学习待迁移场景数据分布以及为特定场景的视觉模式设计了聚类层的算法。这些工作依赖于重新给自动标记的数据以计算权重并加入最后的损失函数以及需要额外的上下文设计以获得可靠的结果。同时，Hattori el al. \cite{hattori2015learning}通过生成空间变化的行人模型来学习特定场景的检测模型。Pishchulin et al. \cite{pishchulin2011learning}利用了一个3D的形状模型来生成训练数据。然而为了场景迁移来进行合成工作也很耗费人力。

\section{检测网络的构建}
~

监控场景在现代生活的应用已经越来越广泛，而对监控场景中的人物进行检测也有着重要的应用价值。监控视频中的人物头部检测大致可以分为两类，一类借助于动态的视频，先提取出固定的背景图片，然后减去背景进行检测；另一类直接从静态的一帧帧图片中，检测出人物头部的区域。然而检测速度慢，误检率高，部署成本高仍然是目前面临的难题。卷积神经网络在计算机视觉领域的巨大成功使得这个任务变得更加可行。我们从静态的图片入手，运用卷积神经网络（Convolutional Neural Network）进行图片检测。卷积神经网络作为编码器将关于图片的特征并表达为特征图时，就需要再加一个解码器将特征图表达为最后的输出。关于将特征图解码有两个可行的方向，一个是直接利用前馈神经网络将特征图转化为特征向量并最后表达为输出，另一个就是利用递归神经网络将特征图的信息解码为一系列的输出。在物体检测的任务中，卷积神经网络+前馈神经网络的方法被广泛采用，然后我们的任务为监控场景下的人头检测，这有别于普通的物体检测。首先监控场景下存在这密集的场景，在某一个时刻可能存在着多达几十个人物出现在场景中；另一个方面，监控场景下的人物相比于普通相机拍到的人物都要更小。这种从物体数量到物体尺寸都跟经典的物体检测的任务有所出处，因此卷积神经网络+前馈神经网络的方法会遇到一些问题。卷积神经网络+递归神经网络的方法可以解决存在多个物体需要检测的情况。


\subsection{卷积神经网络+前馈神经网络的方法}
~



\subsection{卷积神经网络+递归神经网络的方法}
\subsubsection{递归神经网络}
~

在前馈神经网络中，没有办法有效果的对序列的信息进行编码和预测，导致了其在语音处理等序列预测领域有很大的限制。而递归神经网络的出现很好的解决了这个问题。若图所示便是RNN的示意图。在RNN中，输入为可以为一个序列，输出也可以为一个序列。RNN在文字预测方面有着很好的效果，举一个单词预测的例子，当我们输入一个单词的前几个字母，那么如果给出最可能的下一次字母呢？假设我们的词汇量中只有4个可能的字母“helo”,然后我们想要训练一个递归神经网络能够预测“hello”。 这个训练的过程其实就是4个分开的步骤：首先当给定输入为“h”时，那么字母“e”输出的概率应该是最高的，其次给定“he”，那么字母“l”输出的概率应该是最高的，然后给定“hel”，那么字母“l”输出的概率应该是最高的，最后给定“hell”，那么字母“o”输出的概率应该是最高的。需要注意的是，当我们第一次输入“l”时，给出的预测是“l”，当我们第二次输入“l”时，这个时候给出的输出为“o”。由此可以看出递归神经网络并不是只依赖于当前的输入，而是必须一直保留着前文的信息才能够做到这个预测，而FNN是没有办法做到的。在检测阶段，我们将一个字母输入到RNN，然后得到一个关于输出的概率分布。然后我们根据概率从这个分布中采样得到一个可能的输出字母并反馈作为接下来的输入。重复这个过程来得到一系列的字母直到终止。图x给出了RNN的示意图。


RNN的前传跟普通的FNN差不多，除了当信息到达隐含层时，需要同时把当前的输入和前一个时间点的隐含层的输出一起作为输入。为了保持结构上的一致，RNN的第一个时间点可以生成一个无效的前一个时间点的隐含层作为输入。

RNN的问题存在于于长序列进行预测。如果我们只需要根据最近的信息来完成现在的预测，比如上文提到的预测字母的例子，当我们尝试预测“hello worl”的“d”字母时，我们并不需要久之前的信息，而只需要“worl”这几个字母即可，那么我们知道接下来很可能是“d”字母。在这个例子中当前预测所需要的上文信息离当前很近，因此并不存在太大的问题，RNN也可以完成这个任务。然而有些情况下我们需要更多的上文信息，比如我们想要根据“the first program we learned is to print hello w”来预测这边应该是输出“world”。从前文“hello”的信息来看，有可能是接一个含“w”的名词，当我们追溯到更远的“the first program”那么我们知道这很可能是经典的“hello world”，但是对于RNN来说，“the fist program”这个信息来影响当前的预测是比较难得。如果考虑到需要依据的信息和当前的预测更远时，那么RNN几乎无法完成这个任务。有不同的方法尝试着解决这个问题，包括改变误差反传的机制，或者将信息进一步压缩。在这些方法中下过最好的就是下一节讲到的LSTM单元。



\subsubsection{LSTM}
~

在上一个章节中，我们提到了使用RNN所带来的对于序列预测的帮忙，能够将前文的信息也编码到隐含层中，以作为下一个预测的依据。然后标准的RNN框架也面临了极大的问题。这个问题来源于神经网络前传和误差反传的机制，当RNN的所要预测的序列太长时，前文的信息对于后面的预测的影响将是指数级的上升或者下降。解决这个问题最有效的办法就是利用LSTM来取代传统的神经元。图x给出了LSTM的示意图。

一个标准的LSTM网络跟标准的RNN是一样的，除了其中隐含层的神经元都被替换为LSTM单元。一个基本的LSTM包含了一小个集合的递归子网络，称为记忆单元。对于每一个记忆单元，都包含了几个自连通的记忆细胞和三个门，即输入输出和忘记门。这三门也分别对应了对记忆读、写和重置的功能。这三个门是LSTM的核心所在。它们可以在时间推移的过程中，储存或者读取这些记忆，甚至抹除无用的记忆，这样就减轻了随着时间的推移信息难以传递的问题。例如我们通过控制某个LSTM输入门关闭，这样该LSTM中的信息就不会受到新输入的影响，在将来的某一个时刻，保存下来的信息便有可能通过开启输出门使得信息被读取并发挥作用。当忘记门开启式，LSTM便可以忘掉无用的信息，在将来的某一个时刻，通过打开输入门来保存新的记忆信息。在这样一个过程中，LSTM很好的模拟了人脑记忆的思维模式。如果用某一个时刻的隐含层比作人脑的话，那么隐含层中的LSTM单元就对应了人脑的记忆细胞，LSTM单元某一个时刻的值也对应了人脑在某一个时刻的记忆。对于人脑来说，有时候发生了可能影响到未来的事情，比如你在地铁上想到了一个新算法而手头有没有电脑可以实验，那么你就利用自己的记忆在这个新算法记忆下来并在将来有电脑可以使用的情况下触发这个记忆并做相关实验，在实验完成之后发现并没有起效果，于是你就忘了这个算法。对应于LSTM网络，那么当新算法作为输入输入到网络中，LSTM单元及时开启输入门并保存算法信息，当后来的某一个时刻有电脑可以使用时，触发了输出门的开启，于是算法被输出到当前时刻，失败的实验结果也反馈给了LSTM网络，于是它开启了忘记门将这个算法忘记。因此，LSTM很好的模拟了人脑的记忆读取写入和忘记的功能，因此对于长序列的信息也可以做到很好的保存和处理。

\subsection{基于卷积神经网络+递归神经网络的方法的检测网络}
~

在这个章节中我们将介绍我们使用的检测网络的结构。就像上文提到的那样，监控场景下存在这密集的场景，在某一个时刻可能存在着多达几十个人物出现在场景中以及监控场景下的人物相比于普通相机拍到的人物都要更小。这种从物体数量到物体尺寸都跟经典的物体检测的任务有所出处，因此卷积神经网络+前馈神经网络的方法会遇到一些问题。卷积神经网络+递归神经网络的方法可以解决存在多个物体需要检测的情况。在这边我们使用了一个比较新颖的检测网络。这是一个端到端预测的算法。所谓的端到端就是我们将一张图片作为输入，那么网络输出将所有可能的物体区域记忆其置信度。这种端到端直接预测的算法适用于我们的监控场景，相比于其他先提前计算所有可能的区域，然后将这些区域一一通过神经网络来判断做分类要更加的有效果。因为我们场景中的人头存在多而小的问题。同时我们利用了RNN进行序列预测的功能，可能很大程度的避免对同一个物体的重复预测。

\subsubsection{检测模型的构建}
~
我们使用的检测网络首先将一张图片编码为15x20的网格，每个网格内都包含了1024维的GoogLeNet特征向量。同时每个网格对应了输出图片的一个子区域，对于每个网格，子区域中间的64*64区域是鼓励网络取预测的，在这中心区域之外，并不鼓励网络去预测。而64*64的大小已经足够用于捕捉监控场景中人物头部的大小。更大的区域并不能在我们的这个任务中取得更好的效果。对于每一个网格，1024维的向量被分别输入到不同的RNN网络中，之间并不互相影响，但是在最后的结果中将这300个LSTM网络的结果合并在一起。

这里利用到的RNN网络中，每个隐含层包含250个LSTM单元，不带有bias项。在每一个RNN的时间点上，我们将1024维的GoogLeNet特征向量和上一层的隐含层输出拼接在一起作为当前的输入输入给当前的隐含层。


\section{数据集与有监督学习的实验结果}

\subsection{数据集}
~


\subsection{有监督学习的实验结果}
~



\section{我们的迁移方法}
\label{section:Our Approach}

在这个部分中，我们将介绍在人物检测的任务中的无监督场景迁移算法。我们将来自原场景的训练图片标记为${\bf X}^{S} = \{x^{S}_{i}\}^{N^{S}}_{i=1}$， 把待迁移场景中的训练图片标记为${\bf X}^{T} = \{x^{T}_{j}\}^{N^{T}}_{j=1}$。对于原场景中的图片，我们将其对应的标记标记为${\bf B}^{S}_{i} = \{b^{S}_{i,k}\}^{N^{S}_{i}}_{k=1}$，其中$b^{S}_{i,k} = (x,y,w,h) \in R^{4}$。然而待迁移场景中的图片的标记是自动标记的，我们标记为${\bf \tilde{B}}^{T}_{j} = \{\tilde{b}^{T}_{j,k}\}^{N^{T}_{j}}_{k=1}$，其中 $\tilde{b}^{T}_{j,k} = (\tilde{x},\tilde{y},\tilde{w},\tilde{h}) \in R^{4}$。 在迁移的过程中，待迁移场景的标记随着每次迭代而变化。在待迁移场景中，人工标记的数据仅仅用来做迁移算法的评估用。

我们的迁移算法框架分为两个框架流--愿框架流和待迁移框架流。图片x展示了这个框架。愿框架流将原场景的数据作为输入，待迁移框架流将待迁移场景的数据作为输入。这两个框架流可以利用任何的端到端的深度检测网络作为它们的模型。这里我们使用了在章节\ref{section:Detection Network}中介绍的网络作为两个框架流中的模型。在初始化阶段，我们首先利用足够的原场景的标记数据来训练原框架流中的模型，有监督的损失函数来在预测区域进行回归。在训练收敛之后，原框架流的权重用来初始化待迁移框架流中的待迁移模型。在迁移阶段，迭代算法用来作为训练的方法。待迁移框架流中的待迁移模型在迭代过程中被不断更新，同时原框架流中的原模型权重不再更新。

我们的算法同时利用了监督的损失函数和非监督的损失函数来训练学习基于特定场景的检测模型，同时避免训练中的过拟合。对于监督的损失函数，我们利用自动标记的数据作为训练数据。由于自动标记的数据存在数据错误，我么需要利用非监督的损失函数来正则化整个网络。我们将愿框架的原模型作为数据分布的参考。因此我们在迁移过程中结合的无监督和监督的损失函数可以被这样描述：
\begin{eqnarray}
% \nonumber to remove numbering (before each equation)
  L(\theta^{T}|{\bf X}^{S},{\bf B}^{S},{\bf X}^{T},{\bf \tilde{B}}^{T},\theta^{S}) &=& L_{S} + \alpha * L_{U} \\
  L_{S} &=&  \sum^{N^{T}}_{j=1}{\sum^{N^{T}_{J}}_{k=1}( r(\theta^{T}|x^{T}_{j},\tilde{b}^{T}_{j,k})+c(\theta^{T}|x^{T}_{j},\tilde{b}^{T}_{j,k}) )} \\
  L_{U} &=& L_{MMD}(\theta^{T}|{\bf X}^{S},{\bf X}^{T},\theta^{S}) \label{Eq:lmmd}
\end{eqnarray}
其中$L_{S}$是有监督的损失函数来学习基于场景的检测模型，$L_{U}$是无监督的损失函数。$r(\cdot)$是为了预测区域定位的回归函数，比如norm-1损失函数， $c(\cdot)$是为了预测区域置信度的分类函数，比如cross-entroy损失函数。$L_{MMD}(\cdot)$是基于MMD的无监督正则化函数。其中常数$\alpha$用来平衡监督损失函数和无监督损失函数的影响。在我们的实验中，它对于不同的场景具有鲁棒性，我们取$\alpha = 10$作为所有实验的$\alpha$值。


\begin{figure}
\centering
\includegraphics[height=4.5cm]{images/streams.png}
\caption{One kernel at $x_s$ ({\it dotted kernel}) or two kernels at
$x_i$ and $x_j$ ({\it left and right}) lead to the same summed estimate
at $x_s$. This shows a figure consisting of different types of
lines. Elements of the figure described in the caption should be set in
italics,
in parentheses, as shown in this sample caption. The last
sentence of a figure caption should generally end without a full stop}
\label{fig:example}
\end{figure}


\subsection{检测网络}
\label{section:Detection Network}
我们利用Russel et al.提出的模型来作为我们迁移框架流中的模型，这是一个端到端的人物检测模型，它不需要任何提前计算好的可能人物区域。这个检测网络包含了一个GoogLeNet \cite{szegedy2015going}来将一张图片编码为一个(15x20x1024)的特征图，其中每一个1024维都是对应感应区域的数据表征，每一个感应区域对应了原图中的一个子区域。然后一个基于RNN的层将批量大小为300的数据表征解码为具体的300*5个输入，包括预测区域的位置和其对应的置信度。最后所有子图上的输出总结在一起作为最好的检测结果。当我们在原场景的大量数据充分训练之下，得到的深度网络在待迁移场景有较高的准确度，然后它的召回率并不高。同时，不同于其他需要提前计算可能的预测区域并一一给出置信度的检测网络\cite{girshick2015fast,vu2015context}，这个检测网络直接输出了所有的具有高置信度的预测区域。因此，负样本中可能包含人头区域也可能包含非人头区域，这并不能作为迁移时的训练数据。

\begin{figure}
\centering
\includegraphics[height=4.5cm]{images/dummyimage.png}
\caption{One kernel at $x_s$ ({\it dotted kernel}) or two kernels at
$x_i$ and $x_j$ ({\it left and right}) lead to the same summed estimate
at $x_s$. This shows a figure consisting of different types of
lines. Elements of the figure described in the caption should be set in
italics,
in parentheses, as shown in this sample caption. The last
sentence of a figure caption should generally end without a full stop}
\label{fig:example}
\end{figure}


\subsection{迭代算法}
\label{Section:Iterative Algorithm}
这个章节中我们将介绍迁移过程中的迭代算法。自动检测工具将待迁移场景中置信度高的图片作为下一次迭代需要的训练数据。为了生成第一次迭代的自动标记数据，我们利用在原场景充分训练好的原模型来生成待迁移场景的训练数据。就像章节\ref{section:Detection Network}中提到的那样，由原模型自动标记得到的待迁移场景下的训练数据具有低的召回率和高的准确率。在随后的迭代中，每次迭代需要的训练数据都有上一次迭代得到的更新的待迁移模型自动标记得到。在这些迭代中，这些自动标记的图片就作为训练数据来更新待迁移模型。

由于自动标记的待迁移场景的数据包含低的召回率。同时人物区域和非人物区域都混杂在负样本中，我们忽略了低置信度的区域的误差反传。也就是在训练的过程中我们鼓励网络更加大胆的预测正样本，而对于负样本保持保守的态度。这个策略无疑将导致许多非人物的区域都被预测为人物。当错误积累到一定程度，进一步的训练也无法提高召回率，反而适得其反。为了弥补真阴性数据的不足，我们将原场景中人工标记的图片数据加入到训练数据中。在我们的实验中，当训练这些来自原场景的标记图片时，我们只对那些具有低置信度的区域进行反传。同时章节\ref{Section:Unsupervised weights regularizer on Element-wise Multiply Layer}中的无监督损失函数加入了网络中进行正则化约束。完整的迁移算法在算法\ref{algorithm:Deep domain adaptation algorithm (to be completed)}中给出。在一个提前指定的迭代次数极限到达之后，我们就获得了最后的在迁移场景下学习到的检测模型。


\begin{algorithm}
\caption{Deep domain adaptation algorithm (to be completed)}
\label{algorithm:Deep domain adaptation algorithm (to be completed)}
\begin{algorithmic}[1]
\Procedure{Deep domain adaptation} {} \\
\indent Train source model on source stream with abundant annotated data \\
\indent Use well-trained source model on source stream to initialize model on target stream as $M_{0}$
\For{i = 0:$N^{I}$} \\
\indent \indent $M_{i}$ generate "fake ground truth" Gi of target domain \\
\indent \indent balbal \\
\indent \indent balbabla \\
\indent \indent Gi = Gi + random samples from source domain \\
\indent \indent Take Gi as training data to upgrade $M_{i}$ into $M_{i+1}$
\EndFor \\
\indent $M_{N^{I}}$: final model.
\EndProcedure
\end{algorithmic}
\end{algorithm}


\subsection{Unsupervised weights regularizer on Element-wise Multiply Layer}

\subsubsection{Element-wise Multiply Layer}
\label{section:Element-wise Multiply Layer}
~

在深度神经网络中，最后一层的特征向量被作为输入图片的重要表征。然而，在这篇文章中我们往后一步，关注于最后一层的全连通层。这一层作为解码器将最后一层特征向量中包含的丰富信息表达为最后的输出层。由于原模型实在充分的原场景数据下训练得到的，因此其最后一层全连通层的参数也很好的收敛过。我们认为相比于在最后一层的特征向量加入正则化限制，如果在最后这一层全连通层加入了正则化的约束将会取得更好的效果。首先，我们标记最后一层特征向量、最后一层全连通层的参数和最后的输出对应为${\bf F}_{(N^{B}\times N^{D})}$ , ${\bf C}_{(N^{D}\times N^{O})}$ and ${\bf P}_{(N^{B}\times N^{O})}$。最后一层全连通层的操作可以被表达为矩阵乘法：
\begin{eqnarray}
% \nonumber to remove numbering (before each equation)
  {\bf P} &=& {\bf F}*{\bf C} \\
  P_{b,o} &=&  \sum_{d}{F_{b,d}*K_{d,o}}
\end{eqnarray}
从中得到可以得到启发，我们将上述共识切分为两个子操作-- 元素点乘和求和，同样这两个操作可以描述为：
\begin{eqnarray}
% \nonumber to remove numbering (before each equation)
  M_{b,o,d} &=& F_{b,d} * C_{d,o} \\
  P_{b,o} &=& \sum_{d}{M_{b,o,d}}
\end{eqnarray}
其中${\bf M}_{(N^{B}\times N^{O}\times N^{D})} = [\vec{m}_{b,o}]$是元素点乘操作的参数张量。$\vec{m}_{b,o}$ 是一个具有$N^{D}$ 维的向量，这将作为无监督正则化约束的基础。最后，我们可以将最后一层特征向量和最后的输出之间的最后的全连通层转化一个元素点乘层和求和层。这个转化来的元素点乘层是最后一个在输出层之前的带有参数权重的层。图片x展示了这个转化。



\begin{figure}
\centering
\includegraphics[height=4.5cm]{images/mmd.png}
\caption{One kernel at $x_s$ ({\it dotted kernel}) or two kernels at
$x_i$ and $x_j$ ({\it left and right}) lead to the same summed estimate
at $x_s$. }
\label{fig:example}
\end{figure}

\subsubsection{Unsupervised weights regularizer on Element-wise Multiply Layer}
\label{Section:Unsupervised weights regularizer on Element-wise Multiply Layer}
在一些工作中[decaf][][]，最后一层的特征向量被当做图片最后的表征。在场景迁移的任务中，当原模型在在大量原场景数据的训练之下，章节
\ref{section:Element-wise Multiply Layer}中提到的元素点乘层也包含了丰富且重要的信息，直接导致了最后的输出。对于输出层的特定节点来说，它的最后输出值取决于被转化来的最后的元素点乘层，并且元素点乘层每一维对其的贡献并不是随机确定的。在这篇文章中，我们认为原场景和待迁移场景中数据在最后这层元素点乘层的分布应该是相似的。虽然在最后一层元素点乘层中，每一维可能对最后的输出产生影响，但是由于原模型是在大量的原场景的数据的训练之下得到的，那么它在元素点乘层上的分布应该具有代表性，且待迁移模型在迁移的过程中也应该保持一致。这里我们利用MMD (maximum mean discrepancy)来编码原场景数据和待迁移场景数据在元素点乘层上的分布的相似性。
\begin{equation}\label{equation:LMMD}
  L_{MMD}(\theta^{T}|{\bf X}^{S},{\bf X}^{T},\theta^{S}) = \frac{1}{N^{O}} \sum^{N^{O}}_{o=1}{\parallel \frac{1}{N^{B}}\sum^{N^{B}}_{b=1}{\vec{m}^{T}_{b,o}} - \frac{1}{N^{B}}\sum^{N^{B}}_{b=1}{\vec{m}^{S}_{b,o}} {\parallel}^{2}  }
\end{equation}
这个公示也可以解释为对于所有输出节点的$\vec{m}^{T}_{b,o}$ 和 $\vec{m}^{S}_{b,o}$的中心之间的欧式距离的平均值。在实验的过程中，将所有的数据集都拿进来计算数据分布是不现实的，然后数据太少得到的数据分布不稳定，难以做正则化约束，因此在我们的实验中，$L_{MMD}(\cdot)$损失函数是由每一次的批量训练中得到的。$\vec{m}^{S}_{b_{i},o}$和$\vec{m}^{S}_{b_{j},o}$的比较可以在图x中看到。从图中可以看到原场景不同的数据在最后一层元素点乘层的分布是很接近的。



\begin{figure}
\centering
\includegraphics[height=4.5cm]{images/fullconnectlayers.png}
\caption{One kernel at $x_s$ ({\it dotted kernel}) or two kernels at
$x_i$ and $x_j$ ({\it left and right}) lead to the same summed estimate
at $x_s$. }
\label{fig:example}
\end{figure}

\section{实验结果}
\label{section:Experiment Results}

在这个章节中，我们将介绍我们在监控场景中的表现和在标准场景迁移基准数据集上的表现。由于我们最早做场景迁移的动机在于更方便的部署深度检测网络到监控场景中，因此我们首先展示我们在密集场景中人物检测的表现。然后我们将我们的迁移算法应用到标准场景迁移基准数据集上来验证我们的算法的适用性。


\begin{figure}
\centering
\includegraphics[height=4.5cm]{images/precisionrecall.png}
\caption{One kernel at $x_s$ ({\it dotted kernel}) or two kernels at
$x_i$ and $x_j$ ({\it left and right}) lead to the same summed estimate
at $x_s$. This shows a figure consisting of different types of
lines. Elements of the figure described in the caption should be set in
italics,
in parentheses, as shown in this sample caption. The last
sentence of a figure caption should generally end without a full stop}
\label{fig:example}
\end{figure}

\subsection{监控场景中的场景迁移}

\subsubsection{数据集和评估标准}
~

为了展示我们的场景迁移算法在人物检测任务中的效果，我们收集了一个包含了3个待迁移场景的数据集。这三个待迁移场景分别包含了1308，1213和331张没有标记的图片。对于每个场景，我们额外标记了100张图片作为最后的测试数据。我们在人工标记的工程中并不是将整个人的身体都标记出来，而是将其头部标记出来。这样做的原因是在室内的人物检测或者密集场景中的人物检测，由于遮挡等原因，一个人的身体部分很可能是看不到的，选择人物头部作为人物的代表可以解决这个问题。原场景的数据集是来自Brainwash数据集（http://d2.mpi-inf.mpg.de/datasets）。这个数据集包含了超过11917张来自三个场景的带标记的图片。原场景和待迁移场景的示意图如图x所见。

我们对于检测结果的评估方法来自于PASCAL VOC \cite{everingham2015pascal}中所定义的标准。为了判断一个预测区域是不是能够匹配一个真实的人物区域，他们之间的交集面积必须超过他们的合集面积的50\%。如果多个检测结果预测了同一个人物，那么也只能当作一个正确率的预测。我们在图x中画出了准确率-召回率曲线图，同时，在迁移算法的迭代过程中的F1值$F1 = 2*precision*recall/(precision+recall)$也展示在图x中。




\subsubsection{实验设定}
~

我们使用了深度学习框架Caffe \cite{jia2014caffe}作为我们的迁移学习平台。在场景迁移的过程中，我们将网络的学习率设为0.01，动量设为0.5 。在初始化阶段，GoogLeNet的权重首先用来初始化愿框架流的原模型，同时RNN层的参数根据均一分布随机初始化。在每一次迭代中，100张自动标记的待迁移场景的图片和1000张原场景的标记图片交互的用来训练待迁移场景的网络。检测网络的输出包括预测区域的坐标及其对应的置信度，因此在最后一层特征向量和最后的输出之间有两个全连通层。经过我们的实验，发现当无监督的MMD正则化函数已经加到输出预测区域置信度的元素点乘层时，再将无监督的MMD正则化函数加到输出预测区域坐标的元素点乘层并不能更好的表现。我们的迁移算法在3个待迁移场景分别做了实验。



\subsubsection{Comparison with baseline methods}
~

为了展示算法的有效性，我们比较了4个不同的方法，其中方法4是我们最后的迁移算法：
\begin{enumerate}
\item 只有待迁移场景自动标记的数据做训练，不加任何的无监督正则化函数。
\item 只有待迁移场景自动标记的数据做训练，无监督的MMD正则化函数加到最后一层全连通层转化的元素点乘层。
\item 待迁移场景自动标记的数据和来自原场景的标记数据做训练，无监督的MMD正则化函数加到最后一层特征向量层。
\item 待迁移场景自动标记的数据和来自原场景的标记数据做训练，无监督的MMD正则化函数加到最后一层全连通层转化的元素点乘层。
\end{enumerate}
图x画出了上诉几个比较方法的在待迁移场景1中的准确率-召回率曲线。同时，在迁移过程中每一次迭代的F1值的变化也在图x中显示出来。表格x给出了4个比较方法在三个迁移场景下，当F1的值达到最大时相应的准确率和召回率。迁移算法的结果示意图如图x所示。

\begin{table}
\centering
\begin{tabular}{l  c c c c c c c c c c c}
  \hline
  % after \\: \hline or \cline{col1-col2} \cline{col3-col4} ...
    &   \multicolumn{3}{c}{Scene 1}   & & \multicolumn{3}{c}{Scene 2} & &  \multicolumn{3}{c}{Scene 3}   \\
   \cline{2-4} \cline{6-8} \cline{10-12}
    & ~~1-Pr~~ & ~~Re~~ & ~~F1~~ & & ~~1-Pr~~ & ~~Re~~ & ~~F1~~ & & ~~1-Pr~~ & ~~Re~~ & ~~F1~~\\
  \hline
  method 0~~ & 0.101 & 0.187 & 0.309 & ~~ & 0.059 & 0.599 & 0.732 & ~~ & 0.190 & 0.476 & 0.599 \\
  method 1~~ & 0.245 & 0.408 & 0.530 & ~~ & 0.632 & 0.905 & 0.524 & ~~ & 0.176 & 0.778 & 0.800 \\
  method 2~~ & 0.284 & 0.476 & 0.572 & ~~ & 0.012 & 0.837 & {\bf 0.906} & ~~ & 0.078 & 0.653 & 0.764 \\
  method 3~~ & 0.109 & 0.496 & 0.637 & ~~ & 0.002 & 0.721 & 0.838 & ~~ & 0.044 & 0.611 & 0.746 \\
  method 4~~ & 0.140 & 0.530 & {\bf 0.656} & ~~ & 0.006 & 0.811 & 0.893 & ~~ & 0.097 & 0.778 & {\bf 0.836} \\
  \hline
\end{tabular}
\end{table}

\subsubsection{Performance evaluation}
~

从表格x和图x中，我们有以下结论：
\begin{itemize}
  \item 使用了迭代算法来更新待迁移场景中的模型的方法1、2、3、4的召回率数值比直接使用在原场景训练的原模型的方法0更高。这表现了我们的迭代算法在其自动标记和迭代式训练的有效性。
  \item 对比于方法1，方法2有着更高的F1值。他们区别在于是否在损失函数里面添加了无监督的正则化函数，证明了我们的算法可以抑制数据错误同时提高最终的召回率。
  \item 方法4对比于方法2有着更高的F1值，这表明了增加的来自原场景的标记数据有助于减少在迁移过程中针对待迁移场景负样本不反传的错误。
  \item 对比于方法3，方法4的召回率更高了，这表明了转化来的元素点乘层上的无监督正则化函数取得了比特征向量层更好的效果。
\end{itemize}



\subsection{Domain Adaptation on Standard Classification Benchmark}

\subsubsection{Office dataset}
~

Office数据集\cite{saenko2010adapting}包含了来自三个场景(Amazon, DSLR, Webcam)的31个分类。图x给出了样例图片。由于Amazon场景有着最多的2817张标记图片，我们把它作为原场景，将Webcam场景作为待迁移场景。训练数据的使用遵从了标准的有监督和无监督的设定。具体来说，对于无监督学习，我们在原场景Amazon每个类别随机采样了20 张图片作为训练数据，对于有监督学习，我们额外在待迁移场景中每类选取了3个标记图片作为训练数据。在两种实验设定中，剩下的图片都用来作为评估以及用于无监督的MMD正则化计算。

\begin{figure}
\centering
\includegraphics[height=4cm]{images/officeimages.png}
\caption{One kernel at $x_s$ ({\it dotted kernel}) or two kernels at
$x_i$ and $x_j$ ({\it left and right}) }
\label{fig:example}
\end{figure}

\subsubsection{Experimental settings and network design}
~

在有监督的实验设定中，我们服用了在人物检测中的框架流。我们利用AlexNet \cite{krizhevsky2012imagenet}作为两个框架流的基本模型。首先，我们利用Amazon场景提供的训练数据训练愿框架流的原模型。然后在章节\ref{Section:Iterative Algorithm}中的迭代算法作为场景迁移的基本训练方法。自动标记工具将待迁移场景中置信度高于0.9的作为下一次迭代的训练数据。在每一次迭代过程中，随机从训练数据中挑选100张来更新模型。无监督的MMD正则化函数加到最后一层全连通层转化的元素点乘层，损失函数\ref{Eq:lmmd}中常数$\alpha$ 设为10，这同人物检测中利用的常数设定相同。

对于无监督情况，我们使用了于有监督相同的实验设定和网络模型，除了在迁移的过程中，待迁移场景没有提供任何的可以添加到训练数据的人工标记数据。

\subsubsection{Performance evaluation}
~

在表格x中，我们跟6个最近发布的在有监督和无监督设定下的工作的结果。我们的方法在两种设定下都超过了其他方法的结果。这更加证实了我们的迭代算法以及无监督MMD正则化函数加到最后一层全连通层转化的元素点乘层在不同运用下的效果。



\begin{table}
\centering
\begin{tabular}{l c c}
  \hline
  % after \\: \hline or \cline{col1-col2} \cline{col3-col4} ...
   & \multicolumn{2}{c}{A $\rightarrow$ W}    \\
   \cline{2-3}
   ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
   ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    & ~Supervised~ & ~Unsupervised~ \\
  \hline
  GFK(PLS,PCA)\cite{gong2012geodesic} & 46.4 & 15.0 \\
  SA \cite{fernando2013unsupervised} & 45.0 & 15.3 \\
  DA-NBNN \cite{tommasi2013frustratingly} & 52.8 & 23.3 \\
  DLID \cite{chopra2013dlid}& 51.9 & 26.1 \\
  DeCAF${}_{6}$S \cite{donahue2013decaf} & 80.7 & 52.2 \\
  DaNN \cite{ghifary2014domain}& 53.6 & 35.0 \\
  \hline
  Ours & {\bf 84.3} & {\bf 66.3} \\
  \hline
\end{tabular}
\end{table}


\section{Conclusions}
\label{section:Conclusions}

The paper ends with a conclusion.

\begin{figure}
\centering
\includegraphics[height=13cm]{images/detectionresult.png}
\caption{One kernel at $x_s$ ({\it dotted kernel}) or two kernels at
$x_i$ and $x_j$ ({\it left and right}) }
\label{fig:example}
\end{figure}

\bibliographystyle{splncs}
\bibliography{egbib}

\end{CJK*}
\end{document}
